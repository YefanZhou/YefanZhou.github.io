<!DOCTYPE HTML>
<html lang="en"><head>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-TF5SPSGGYM"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-TF5SPSGGYM');
</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-EZFRNCT6W3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-EZFRNCT6W3');
</script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yefan Zhou</title>

  <meta name="author" content="Yefan Zhou">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:75%;vertical-align:left">
              <p style="text-align:center">
                <name>Yefan Zhou</name>
              </p>
              <p class="intro">Hi, I'm Yefan. I am a second-year CS PhD student (2023- ) at Dartmouth College advised by <a href="https://sites.google.com/site/yangyaoqingcmu/">Prof. Yaoqing Yang</a>. I am a researcher at <a href="https://www.icsi.berkeley.edu/icsi/">UC Berkeley/ICSI</a> working with <a href="https://www.stat.berkeley.edu/~mmahoney/">Prof. Michael Mahoney</a>.<br>
                I earned my <a href="https://eecs.berkeley.edu/">Master's degree in EECS</a> at UC Berkeley.<br>
              </br>
              
                <br>
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=TAeVaicAAAAJ">Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/YefanZhou"><i class="fa fa-github" style="font-size:24px"></i></a> &nbsp/&nbsp
                <a href="https://twitter.com/LiamZhou98"><i class="fa fa-twitter" style="font-size:24px"></i></a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/yefan-zhou-b430541b1/">Linkedin</a> &nbsp/&nbsp
                <a href="mailto:yefan0726@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://github.com/YefanZhou/YefanZhou.github.io/blob/master/data/resume_yefan_04_11_2024.pdf">Resume</a>
              </p>
            </td>
           <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile-circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in improving efficiency and transparency of machine learning models. 
                My current research is focused on model diagnosis, utilizing <a href="https://sites.google.com/view/hidimlearning23/home?authuser=0">high-dimension features</a> such as <a href="https://www.youtube.com/watch?v=aq3oA6jSGro&t=11s">loss landscapes</a>, <a href="https://sites.google.com/view/heavy-tails-ml-2023">weight matrix analysis</a>. 
                This research contributes to practical ML development, including neural network training, model compression and hyperparameter tuning.
              </p>
            </td>
          </tr>
        

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <heading>Selected first-author paper</heading>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/tempbalance.png' width="300"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2312.00359">
                <papertitle>Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training</papertitle>
              </a>
              <br>
              {<strong>Yefan Zhou*</strong>,
              Tianyu Pang*},
              Keqin Liu,
              Charles H. Martin,
              <a href="https://www.stat.berkeley.edu/~mmahoney/">Michael Mahoney</a>,
              <a href="https://sites.google.com/site/yangyaoqingcmu/">Yaoqing Yang</a>,
              <br>
              <em>Neural Information Processing Systems (NeurIPS)</em>, 2023, Spotlight
              <br>
              <a href="https://arxiv.org/abs/2312.00359">Paper</a> /
              <a href="https://github.com/YefanZhou/TempBalance">Code</a> /
              <a href="https://recorder-v3.slideslive.com/?share=87192&s=14ff4069-14ea-4f19-bf8b-368a2db26dfd">Video</a> 
              <p></p>
              <p>
                Most deep neural networks have complex multilayer structures, often seen as a barrier to transparency. 
                In our research, we reveal a significant insight: these layers are not uniformly well-trained. 
                We introduce a new training method that utilizes "model diagnostic" tool to identify and address underperforming layers, 
                and enhance the overall network quality.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/alphaprune.png' width="300"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <papertitle>AlphaPruning: Using Heavy-Tailed Self Regularization Theory for Improved Layer-wise Pruning of Large Language Models</papertitle>
              </a>
              <br>
              {Haiquan Lu*,
              <strong>Yefan Zhou*</strong>},
              Shiwei Liu,
              Zhangyang Wang,
              Michael W. Mahoney,
              Yaoqing Yang
              <br>
              <em>Neural Information Processing Systems (NeurIPS)</em>, 2024
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/sharpb.png' width="300"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2407.12996">
                <papertitle>Sharpness-diversity tradeoff: improving flat ensembles with SharpBalance</papertitle>
              </a> 
              <br>
              {Haiquan Lu*, 
              Xiaotian Liu*, 
              <strong>Yefan Zhou</strong>*, 
              Qunli Li*}, 
              Kurt Keutzer, 
              Michael W. Mahoney, 
              Yujun Yan, 
              Huanrui Yang, 
              Yaoqing Yang
              <br>
              <em>Neural Information Processing Systems (NeurIPS)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2407.12996">Paper</a> /
              <p></p>
              <p>
                We discover a trade-off between sharpness and diversity: minimizing the sharpness in the loss landscape tends to diminish the diversity of members within the ensemble, adversely affecting the ensemble's improvement. We introduce a new ensemble training method called SharpBalance to address it.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/md_tree.png' width="300"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a>
                <papertitle>MD tree: a model-diagnostic tree grown on loss landscape</papertitle>
              </a>
              <br>
              {<strong>Yefan Zhou*</strong>,
              Jianlong Chen*},
              Qinxue Cao,
              Konstantin Schürholt,
              Yaoqing Yang,
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2406.16988">Paper</a> /
              <a href="https://github.com/YefanZhou/ModelDiagnosis">Code</a> /
              <a href="https://www.youtube.com/watch?v=9S-MHSiune0&t=18s">Video</a>
              <p></p>
              <p>
              </p>
            </td>
          </tr>

          

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/overview_sharp.png' width="300"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2305.18383">
                <papertitle>A Three-regime model of Network Pruning</papertitle>
              </a>
              <br>
              <strong>Yefan Zhou</strong>,
              <a href="https://sites.google.com/site/yangyaoqingcmu/">Yaoqing Yang</a>,
              <a href="https://arinchang.github.io/">Arin Chang</a>,
              <a href="https://www.stat.berkeley.edu/~mmahoney/">Michael Mahoney</a>
              <br>
              <em>International Conference on Machine Learning (ICML)</em>, 2023
              <br>
              <a href="https://proceedings.mlr.press/v202/zhou23p.html">Paper</a> /
              <a href="https://github.com/YefanZhou/ThreeRegimePruning">Code</a> /
              <a href="https://slideslive.com/39002670/a-threeregime-model-of-network-pruning?locale=cs">Video</a> 
              <p></p>
              <p>
                The study identifies a transition phenomenon in neural network pruning, where the effect of increasing the temperature-like parameter (e.g. training epochs) depends on the value of the load-like parameter (e.g. pruning ratio), leading to different pruning outcomes. 
                The findings are then applied to three practical scenarios, 
                including optimizing hyperparameters for improved pruning and selecting the most suitable model for pruning.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/3d_ds.png' width="300"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2111.15158">
                <papertitle>A Dataset-dispersion Perspective on Reconstruction versus Recognition in Single-view 3D Reconstruction Networks</papertitle>
              </a>
              <br>
              <strong>Yefan Zhou</strong>,
              <a href="https://scholar.google.com/citations?user=-_Hy9z0AAAAJ&hl=en">Yiru Shen</a>,
              <a href="https://people.eecs.berkeley.edu/~wguo/">Yujun Yan</a>,
              <a href="https://engineering.nyu.edu/faculty/chen-feng">Chen Feng</a>,
              <a href="https://sites.google.com/site/yangyaoqingcmu/">Yaoqing Yang</a>
              <br>
              <em>International Conference on 3D Vision (3DV)</em>, 2021
              <br>
              <a href="https://arxiv.org/abs/2111.15158">arXiv</a> /
              <a href="https://github.com/YefanZhou/dispersion-score">Github</a> /
              <a href="https://3dv2021.surrey.ac.uk/accepted-papers/">3DV 2021</a> /
              <a href="https://slideslive.com/38972241/">Video</a>
              <p></p>
              <p>
                A SVR model can be disposed towards recognition (classification-based) or reconstruction depending on how dispersed the training data becomes.<br>
                We propose "dispersion score", which is a data-driven metric used to measure the tendency of SVR models to perform recognition or reconstruction. 
                It can also be used to diagnose problems from the training data and guide the design of data augmentation schemes.
              </p>
            </td>
          </tr>
          
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <heading>Collaborating paper</heading>




          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!--   <img src='images/mlgsl.png' width="320"></div>--> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>	Model Balancing Helps Low-data Training and Fine-tuning</papertitle>
                <br>  
              Zihang Liu,
              Yuanzhe Hu,
              Tianyu Pang
              <strong>Yefan Zhou</strong>,
              Pu Ren,
              Yaoqing Yang
              <br>
              <em>Empirical Methods in Natural Language Processing (EMNLP main)</em>, 2024
              <br>
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>
          

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!--   <img src='images/mlgsl.png' width="320"></div>--> 
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>AlphaExpert: Assigning LoRA Experts Based on Layer Training Quality</papertitle>
                <br>  
              Peijun Qing,
              Chongyang Gao,
              <strong>Yefan Zhou</strong>,
              Xingjian Diao,
              Pu Ren,
              Yaoqing Yang,
              Soroush Vosoughi
              <br>
              <em>Empirical Methods in Natural Language Processing (EMNLP main)</em>, 2024
              <br>
              <br>
              <p></p>
              <p>
              </p>
            </td>
          </tr>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/mlgsl.png' width="320"></div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.01379">
                <papertitle>Learn to Grasp with Less Supervision: A Data-Efficient Maximum Likelihood Grasp Sampling Loss</papertitle>
              </a>
                <br>  
              <a href="https://rolandzhu.github.io/">Xinghao Zhu</a>,
              <strong>Yefan Zhou</strong>,
              <a href="https://scholar.google.com/citations?user=YAGWw68AAAAJ&hl=en">Yongxiang Fan</a>,
              <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/">Jianyu Chen</a>,
              <a href="https://me.berkeley.edu/people/masayoshi-tomizuka/">Masayoshi Tomizuka</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA)</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2110.01379">arXiv</a> /
              <a href="https://www.icra2022.org/">ICRA 2022</a> /
              <a href="https://youtu.be/vHTMWdj4n7o">Video</a>
              <br>
              <p></p>
              <p>
                Empirical grasping datasets are typically sparsely labeled (i.e., a small number of successful grasp labels in each image). <br> We propose a maximum likelihood grasp sampling loss (MLGSL) for learning robotic grasping from sparsely labeled datasets. <br> MLGSL is 8× more data-efficient than SOTA with a 91.8% grasp success rate in real-world experiments.
              </p>
            </td>
          </tr>


          



        </tbody></table>
        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic service</heading> 
              <p>ICML 2024, CAPL 2024, ICLR 2024-2025, CVPR 2024, NeurIPS 2023, IROS 2022, TMLR</p>
            </td>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Projects</heading>
              </td>
            </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="staff_stop()" onmouseover="staff_start()">
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>H-PG: Hybrid Deep Reinforcement Learning with Robotic Grasp Planning</papertitle>
              <br>
              <strong>Yefan Zhou</strong>, <a href="https://www.linkedin.com/in/xiangyu1998/">Xiangyu Zhou</a> and <a href="https://www.linkedin.com/in/jerry-ge-12b840124/">Jerry Ge</a>
              <br>
              <a href="https://www.youtube.com/watch?v=YFV3_CLpEdk">Video</a> /
              <a href="data/CS285_FinalProject_ICLR.pdf">PDF</a>
                <p>
                  We proposed Hybrid Policy Gradient (H-PG), a novel deep reinforcement learning framework for robotic grasping task defined in continuous-discrete hybrid action space; <br> H-PG improves baseline by 7.4% of grasp success rate on YCB dataset in PyBullet simulator.
                  <br><br>
                </p>
            </td>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="two" id='cover'>
                  <img src='images/h_pg.png' width="350"></div>
              <div class="one" id='viz'>
                  <img src='images/h_pg_comp.png' width="380">
              </div>              <br>
              <script type="text/javascript">
              function staff_start() {
                document.getElementById('viz').style.opacity = "1";
                document.getElementById('cover').style.opacity = "0";
              }

              function staff_stop() {
                document.getElementById('viz').style.opacity = "0";
                document.getElementById('cover').style.opacity = "1";
              }
              staff_stop()
            </script>
            </td>
          </tr>

        
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <a href="https://jonbarron.info/">Website template</a>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
