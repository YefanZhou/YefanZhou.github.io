---
title: "Learn to Grasp with Less Supervision: A Data-Efficient Maximum Likelihood Grasp Sampling Loss"
collection: talks
type: "Research Assistant"
permalink: /talks/pointcloud
venue: "<br/> Supervisor: &emsp; Masayoshi Tomizuka, UC Berkeley"
date: 2021-03-05
location: "Berkeley, CA"
---

This work proposes a Maximum Likelihood Grasp Sampling Loss (MLGSL) to tackle the data sparsity issue in deep grasping model training. My main contributions are:
* Proposed and integrated spatial attention module (SAM) into fully connected grasp generation neural network. Experimentally demonstrated the effect of SAM module in reducing the action sampling complexity by providing a region of importance.
* Constructed a cluttered object dataset based on Jacquard Dataset by randomly selecting a few images from the single object dataset and combined them into a cluttered sample, including image augmentation and grasp collision pruning.
